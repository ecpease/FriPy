{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull NWIS Data using a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Start timer to see how long it takes for your script to run\n",
    "startTime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_nwis_data(parameter, site_number, start_date, end_date, site_name):\n",
    "    nwis_url = f'https://waterdata.usgs.gov/nwis/dv?cb_{parameter}=on&cb_72137=on&format=rdb&site_no={site_number}&referred_module=sw&period=&begin_date={begin_date}&end_date={end_date}'.format(parameter,site_id,begin_date,end_date)\n",
    "    print(nwis_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n",
      "Dormammu I have come to bargain\n"
     ]
    }
   ],
   "source": [
    "    # Find where in the file the data actually starts and skip rows\n",
    "    for sr in range(25, 35):\n",
    "        try:\n",
    "            df = pd.read_table(discharge_url, skiprows=sr)\n",
    "            if df.columns.values[0] == '5s':\n",
    "                break\n",
    "        except:\n",
    "            print('Dormammu I have come to bargain') # Dr. Strange reference anyone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Site', 'DateTime', 'Tz', '{parameter}', 'qual_code']\n"
     ]
    }
   ],
   "source": [
    "    # Rename the columns to something easier to read\n",
    "    columns = ['Name', 'Site', 'DateTime', 'Tz', '{parameter}', 'qual_code']\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Name Site  DateTime Tz  {parameter} qual_code\n",
      "USGS 8162501 2017-07-13  1.41    P      0.78  P        913.0         P\n",
      "             2017-07-14  1.31    P      0.75  P        958.0         P\n",
      "             2017-07-15  1.37    P      0.70  P       1110.0         P\n",
      "             2017-07-16  1.49    P      0.90  P       1310.0         P\n",
      "             2017-07-17  1.70    P      0.84  P       1310.0         P\n"
     ]
    }
   ],
   "source": [
    "    # Read the table, skipping the rows\n",
    "    df = pd.read_table(nwis_url, skiprows=sr+1, names=columns)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Convert to DateTime\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], format='%Y-%m-%d %H:%M:%S')  \n",
    "    df.index = df['DateTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'site_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9a2014d1ba95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Export to csv with the title you give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msite_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'site_name' is not defined"
     ]
    }
   ],
   "source": [
    "    # Export to csv with the title you give \n",
    "    df.to_csv({site_name}+'.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "Shoal_Ck = get_nwis_discharge(parameter='00060', site_id='08156800', begin_date='2018-03-01', end_date='2018-03-18', site_name='USGS 08156800 Shoal Ck at W 12th St, Austin, TX')\n",
    "print(Shoal_Ck.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
